---
title: "Tidy Text Notebook"
author: "Sean Nguyen"
subtitle: By David Robinson and Julia Silge
output:
  html_document:
    df_print: paged
    theme: flatly
  html_notebook: default
  pdf_document: default
---

This is my notebook that I will used to go through the tidy text notebook by Julia Silge and David Robinson. 

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidytext)
library(stringr)
library(janeaustenr)


text <- c("Because I could not stop for Death - ", 
          "He kindly stopped for me -",
          "The Carriage held but just Ourselves -",
          "and Immortality")

text
```

```{r}
text_df <- data_frame(line = 1:4, text = text)

text_df
```
```{r}
text_df %>% 
  unnest_tokens(word, text)  # to_lower = FALSE to keep uppercase
```

###Working with Jane Austen Books

Using the Jane Austen dataset we can make it tidy.  First we'll use mutate to create a column from existing data.  Annotate line numbers and then keep track of chapters using regex.

```{r}
original_books <- austen_books() %>% 
  group_by(book) %>% 
  mutate(linenumber = row_number(),
         chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
                                                  ignore.case = TRUE)))) %>% 
  ungroup()

original_books
```

Restructure it in *one-token-per-row* format with the **unnest_tokens()** function.

```{r}
tidy_books <- original_books %>% 
  unnest_tokens(word, text)

tidy_books
```
 
####Removing stop words
We can remove *stop words* 

```{r}
data(stop_words)

tidy_books <- tidy_books %>% 
  anti_join(stop_words)

tidy_books %>% 
  count(word, sort = TRUE)


```

Plotting data 

```{r}
tidy_books %>% 
  count(word, sort = TRUE) %>% 
  filter(n > 600) %>% 
  mutate(word = reorder(word, n)) %>% 
  ggplot(aes(word, n))+
  geom_col()+
  xlab(NULL)+
  coord_flip()+
  theme_bw()
```
#### Gutenbergr

HG wells books
```{r}
library(gutenbergr)


hgwells <-  gutenberg_download(c(35, 36, 5230, 159))

tidy_hgwells <- hgwells %>% 
  unnest_tokens(word, text) %>% 
  anti_join(stop_words)

tidy_hgwells %>% 
  count(word, sort = TRUE)
```

Most commone words in novels by Bronte sisters

```{r}
bronte <-  gutenberg_download(c(1260, 768, 969, 9182, 767))

tidy_bronte <- bronte %>% 
  unnest_tokens(word, text) %>% 
  anti_join(stop_words)

tidy_bronte %>% 
  count(word, sort = TRUE)

```

Comparing Bronte and HG Wells

```{r}
frequency <- bind_rows(mutate(tidy_bronte, author = "Bronte Sisters"),
                       mutate(tidy_hgwells, author = "H.G. Wells"),
                       mutate(tidy_books, author = "Jane Austen")) %>% 
  mutate(word = str_extract(word, "[a-z']+")) %>% 
  count(author, word) %>% 
  group_by(author) %>% 
  mutate(proportion = n / sum(n)) %>% 
  select(-n) %>% 
  spread(author, proportion) %>% 
  gather(author, proportion, `Bronte Sisters`:`H.G. Wells`)
```

###Graphing the comparisons

```{r}
library(scales)

ggplot(frequency, aes(x = proportion, y = `Jane Austen`,
                      color = abs(`Jane Austen` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word, check_overlap = TRUE, vjust = 1.5))+
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0,0.001),
                       low = "darkslategray4", high = "gray75") +
  facet_wrap(~author, ncol = 2) +
  theme(legend.position = "none") +
  labs(y = "Jane Austen", x = NULL)
  
```

###Correlation analysis
```{r}
cor.test(data = frequency[frequency$author == "Bronte Sisters",],
         ~ proportion + `Jane Austen`)
```

```{r}
cor.test(data = frequency[frequency$author == "H.G. Wells",],
         ~ proportion + `Jane Austen`)
```

# Sentiments dataset

```{r}
library(tidytext)

sentiments
```
Sentiment scores
```{r}
# AFINN
get_sentiments("afinn")
# Bing
get_sentiments("bing")
# NRC
get_sentiments("nrc")
```
 Sentiment analysis can be performed with an **inner join**
 
 
```{r}
tidy_books <- austen_books() %>% 
  group_by(book) %>% 
  mutate(linenumber = row_number(),
         chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
                                                 ignore_case = TRUE)))) %>% 
  ungroup() %>% 
  unnest_tokens(word, text)

tidy_books
```

Get a list of words that are associated with 'joy' and perform an inner_join to find words that are have 'joy' sentiment within Jane Austen's Emma book.
```{r}

# Filter words associated with 'joy'
nrcjoy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")

# Find words associated with joy in Emma
tidy_books %>% 
  filter(book == "Emma") %>% 
  inner_join(nrcjoy) %>% 
  count(word, sort = TRUE)
```
Count up positive or negative words that are within sections of each book.  We will define an index to keep track of where we are in the narrative.  The index will count up sections of 80 lines of text
```{r}
janeaustensentiment <- tidy_books %>% 
  inner_join(get_sentiments("bing")) %>% 
  count(book, index = linenumber %/% 80, sentiment) %>% 
  spread(sentiment, n, fill =0) %>% 
  mutate(sentiment = positive - negative)

janeaustensentiment
```
```{r}
ggplot(janeaustensentiment, aes(index, sentiment, fill = book)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~book, ncol = 2, scales = "free_x")
```

```{r}
pride_prejudice <- tidy_books %>% 
  filter(book == "Pride & Prejudice")

pride_prejudice
```
```{r}
afinn <- pride_prejudice %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = linenumber %/% 80) %>% 
  summarise(sentiment = sum(score)) %>% 
  mutate(method = "AFINN")

afinn

```
```{r}
bing_and_nrc <- bind_rows(
  pride_prejudice %>% 
    inner_join(get_sentiments("bing")) %>% 
    mutate(method = "Bing et al."),
  pride_prejudice %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive",
                                         "negative"))) %>% 
    mutate(method = "NRC")) %>% 
    count(method, index = linenumber %/% 80, sentiment) %>% 
    spread(sentiment, n, fill = 0) %>% 
    mutate(sentiment = positive - negative)

bing_and_nrc
```
Comparing three sentiment lexicons using Pride and Prejudice
```{r}
bind_rows(afinn,
          bing_and_nrc) %>% 
  ggplot(aes(index, sentiment, fill = method)) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~method, ncol = 1 , scales = "free_y")
```
```{r}
get_sentiments("nrc") %>% 
  filter(sentiment %in% c("positive",
                          "negative")) %>% 
  count(sentiment)


get_sentiments("bing") %>% 
  count(sentiment)
```
```{r}
bing_words_counts <- tidy_books %>% 
  inner_join(get_sentiments("bing")) %>% 
  count(word, sentiment, sort = TRUE) %>% 
  ungroup()

bing_words_counts
```
```{r}
bing_words_counts %>% 
  group_by(sentiment) %>% 
  top_n(10) %>% 
  ungroup() %>% 
  mutate(word = reorder(word, n)) %>% 
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE)+
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL,
       title = "Top 10 words by Sentiment for Pride and Prejudice") +
  coord_flip()
```
Miss is referred to as a negative word but is not in Jane Austen's works.
```{r}
custom_stop_words <- bind_rows(data_frame(word = c("miss"),
                                          lexicon = c("custom")),
                               stop_words)

custom_stop_words
```
# Wordclouds

```{r}
library(wordcloud)

tidy_books %>% 
  anti_join(stop_words) %>% 
  count(word) %>% 
  with(wordcloud(word, n, max.words = 100))
```

```{r}
library(reshape2)

tidy_books %>% 
  inner_join(get_sentiments("bing")) %>% 
  count(word, sentiment, sort = TRUE) %>% 
  acast(word~sentiment, value.car = "n", fill = 0) %>% 
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)
```

Looking at Units Beyond Just Words
```{r}
PandP_sentences <-  data_frame(text = prideprejudice) %>% 
  unnest_tokens(sentence, text, token = "sentences")
```

```{r}
PandP_sentences$sentence[2]
```
Figuring out how many chapters are in a book
```{r}
austen_chapters <- austen_books() %>% 
  group_by(book) %>% 
  unnest_tokens(chapter, text , token = "regex",
                pattern = "Chapter|CHAPTER [\\dIVXLC]") %>% 
  ungroup()


austen_chapters %>% 
  group_by(book) %>% 
  summarise(chapters = n())
```


```{r}
bingnegative <- get_sentiments("bing") %>% 
  filter(sentiment == "negative")

wordcounts <- tidy_books %>% 
  group_by(book, chapter) %>% 
  summarize(words = n())

tidy_books %>% 
  semi_join(bingnegative) %>% 
  group_by(book, chapter) %>% 
  summarize(negativewords = n()) %>% 
  left_join(wordcounts, by = c("book", "chapter")) %>% 
  mutate(ratio = negativewords/words) %>% 
  filter(chapter !=0) %>% 
  top_n(1) %>% 
  ungroup()
```
 
 # Chapter 3
 
 Term Frequency in Jane Austen's Novels
 
```{r}
book_words <- austen_books() %>% 
  unnest_tokens(word,text) %>% 
  count(book,word,sort = TRUE) %>% 
  ungroup()

total_words <- book_words %>% 
  group_by(book) %>% 
  summarize(total = sum(n))

book_words <- left_join(book_words, total_words)

book_words
```

Term frequency distribution in Jane Austen's novels
```{r}
ggplot(book_words, aes(n/total, fill = book)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.0009) +
  facet_wrap(~book, ncol = 2, scales = "free_y")
  
```

Zipf's Law

Zipf's Law: frequency that a word appears is inversely proportional to its rank.

```{r}
freq_by_rank <- book_words %>% 
  group_by(book) %>% 
  mutate(rank = row_number(),
         'term frequency' = n/total)

freq_by_rank
```

Graph of Zipf's law for Jane Austen's novels
```{r}

freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = book)) +
  geom_line(size = 1.1, alpha = 0.8, show.legend = TRUE) +
  scale_x_log10() +
  scale_y_log10()
```

```{r}
rank_subset <-  freq_by_rank %>% 
  filter(rank <500,
         rank >10)


lm(log10(`term frequency`) ~ log10(rank), data = rank_subset)
```
```{r}
freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = book))+
  geom_abline(intercept = -0.62, slope = -1.1, color = "gray50", linetype = 2) +
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) +
  scale_x_log10() +
  scale_y_log10()

```

The bind_tf_idf Function

```{r}
book_words <- book_words %>% 
  bind_tf_idf(word, book, n)

book_words
```

```{r}
book_words %>% 
  select(-total) %>% 
  arrange(desc(tf_idf))
```

```{r}
book_words %>% 
  arrange(desc(tf_idf)) %>% 
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(book) %>% 
  top_n(15) %>% 
  ungroup() %>% 
  ggplot(aes(word, tf_idf, fill = book)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~book, ncol = 2,scales = "free") +
  coord_flip()
```
A corpus of Physics Text

```{r}
physics <- gutenberg_download(c(37729, 14725, 13476, 5001),
                              meta_fields = "author")
```

```{r}
physics_words <- physics %>% 
  unnest_tokens(word, text) %>% 
  count(author, word, sort = TRUE) %>% 
  ungroup()

physics_words
```

```{r}
author_order <- c("Galilei, Galileo", "Huygens, Christiaan", "Tesla, Nikola", "Einstein, Albert")

plot_physics <- physics_words %>% 
  bind_tf_idf(word, author, n) %>% 
  arrange(desc(tf_idf)) %>% 
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  mutate(author = factor(author, levels = author_order))

plot_physics
```

```{r}
plot_physics %>% 
  group_by(author) %>%
  top_n(15, tf_idf) %>% 
  ungroup() %>% 
  mutate(word = reorder(word, tf_idf)) %>% 
  ggplot(aes(word, tf_idf, fill = author)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~author, ncol = 2, scales = "free") +
  coord_flip()
  

```

Isolating "eq" from Einstein's text

```{r}
physics %>% 
  filter(str_detect(text, "eq\\.")) %>% 
  select(text)
```
K1 was used for the coordinate system for Einstein
```{r}

physics %>%
  filter(str_detect(text, "K1")) %>% 
  select(text)

  
```
```{r}
physics %>%
  filter(str_detect(text, "AK")) %>% 
  select(text)
```

```{r}
mystopwords <- data_frame(word = c("eq","co","rc","ac","ak","bn",
                                   "fig", "file", "cg", "cb", "cm"))

physics_words <- anti_join(physics_words, mystopwords, by = "word")

plot_physics <- physics_words %>% 
  bind_tf_idf(word, author, n) %>% 
  arrange(desc(tf_idf)) %>% 
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(author) %>% 
  top_n(15, tf_idf) %>% 
  ungroup() %>% 
  mutate(author = factor(author, levels = author_order))

plot_physics
```

```{r}
ggplot(plot_physics, aes(word, tf_idf, fill = author)) +
  geom_col(show.legend = FALSE) +
  labs( x = NULL, y = "tf-idf") +
  facet_wrap(~author, ncol = 2, scales = "free") +
  coord_flip()

```

# Chapter 4 Relationships Between Words: N-grams and Correlations

```{r}
austen_bigrams <- austen_books() %>% 
  unnest_tokens(bigram, text, token = "ngrams", n = 2)

austen_bigrams

```
Counting and Filtering N-grams
```{r}
austen_bigrams %>% 
  count(bigram, sort = TRUE)
```

```{r}
bigrams_separated <-  austen_bigrams %>% 
  separate(bigram, into = c("word1", "word2"), sep = " ")
  
bigrams_filtered <- bigrams_separated %>% 
  filter(!word1 %in% stop_words$word) %>% 
  filter(!word2 %in% stop_words$word)


bigram_counts <- bigrams_filtered %>% 
  count(word1, word2, sort = TRUE)

bigram_counts
```

```{r}
bigrams_united <- bigrams_filtered %>% 
  unite(bigram, word1, word2, sep = " ")

bigrams_united
```

```{r}

austen_books() %>% 
  unnest_tokens(trigram, text, token = "ngrams", n = 3) %>% 
  separate(trigram, into = c("word1", "word2", "word3"), sep = " ") %>% 
  filter(!word1 %in% stop_words$word,
         !word2 %in% stop_words$word,
         !word3 %in% stop_words$word) %>% 
  count(word1, word2, word3, sort = TRUE)
```

###Analyzing Bigrams

Identifying the "streets" in each book.

```{r}
bigrams_filtered %>% 
  filter(word2 == "street") %>% 
  count(book, word1, sort = TRUE)
```

```{r}
bigram_tf_idf <- bigrams_united %>% 
  count(book, bigram) %>% 
  bind_tf_idf(bigram, book, n) %>% 
  arrange(desc(tf_idf))

bigram_tf_idf 
```

The 12 bigrams with the highest tf-idf from each Jane Austen novel.
```{r}
bigram_tf_idf %>% 
  arrange(desc(tf_idf)) %>% 
  mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %>% 
  group_by(book) %>% 
  top_n(12,tf_idf) %>% 
  ungroup() %>% 
  ggplot(aes(x = bigram, y = tf_idf, fill = book))+
    geom_col(show.legend = FALSE) +
    facet_wrap(~book, ncol = 2, scales = "free")+
    coord_flip()

```
Using Bigrams to Provide Context in Sentiment Analysis
```{r}
bigrams_separated %>% 
  filter(word1 == "not") %>% 
  count(word1, word2, sort = TRUE)
```

```{r}
AFINN <- get_sentiments("afinn") 

AFINN
```

```{r}
not_words <- bigrams_separated %>% 
  rename(word = word2) %>% 
  filter(word1 == "not") %>% 
  inner_join(AFINN) %>% 
  count(word, score, sort = TRUE) %>% 
  ungroup()
    
    
not_words
  
```



The 20 sords followed by "not" that had the greatest contribution to sentiment scores, in either a postivie or negative direction.
```{r}
not_words %>% 
  mutate(contribution = n * score) %>% 
  arrange(desc(abs(contribution))) %>% 
  head(20) %>% 
  mutate(word = reorder(word, contribution)) %>% 
  ggplot(aes(word, n * score, fill = n * score > 0)) +
  geom_col(show.legend = FALSE) +
  xlab("Words preceded by \"not\"") +
  ylab("Sentiment score * number of occurences") +
  coord_flip()
```

```{r}
negation_words <- c("not", "no", "never", "without")

negated_words <- bigrams_separated %>% 
  filter(word1 %in% negation_words) %>% 
  inner_join(AFINN, by = c(word2 = "word")) %>% 
  count(word1, word2, sort = TRUE) %>% 
  ungroup()



negated_words %>% 
  inner_join(not_words) %>% 
  mutate(contribution = n * score) %>% 
  arrange(desc(abs(contribution))) %>% 
  head(12) %>% 
  mutate(word = reorder(word, contribution)) %>% 
  ggplot(aes(word, n * score, fill = n * score > 0)) +
  geom_col(show.legend = FALSE) +
  xlab("Words preceded by \"not\"") +
  ylab("Sentiment score * number of occurences") +
  coord_flip() +
  facet_wrap(~word1)
```


Analyzing networks with igraph.

Create an igraph object from tidy data using the 'graph_from_data_frame()' function, which takes a data frame of edges with columns for "from", "to" and edge attributes (in this case n).

```{r}
library(igraph)

bigram_counts


bigram_graph <- bigram_counts %>% 
  filter(n > 20) %>% 
  graph_from_data_frame()

bigram_graph
  
```

Commone bigrams in Pride and Prejudice, showing those that occurred more thatn 20 times and where neighter word was a stop word
```{r}
library(ggraph)

set.seed(2017)

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link() +
  geom_node_point() +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1)


```
Common bigrams in Pride and Prejudice, with some polishing
```{r}
set.seed(2016)


a <- grid::arrow(type = "closed", length = unit(.15, "inches"))

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "lightblue", size = 5) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()



```

#Topicmodels package
```{r}
library(tm)

data("AssociatedPress", package = "topicmodels")

AssociatedPress
```

```{r}
terms <- Terms(AssociatedPress)
head(terms)
```

```{r}
# library(tidyverse)
# library(tidytext)

ap_td <- tidy(AssociatedPress)
ap_td
```

```{r}
ap_sentiments <- ap_td %>% 
  inner_join(get_sentiments("bing"), by = c( term = "word"))


ap_sentiments
```

```{r}
# ggplot2

ap_sentiments %>% 
  count(sentiment, term, wt = count) %>% 
  ungroup() %>% 
  filter(n>= 200) %>% 
  mutate(n = ifelse(sentiment == "negative", -n, n)) %>% 
  mutate(term = reorder(term, n)) %>% 
  ggplot(aes(term, n, fill = sentiment)) +
  geom_col() +
  ylab("Contribution to sentiment") +
  coord_flip()
```

```{r}
library(methods)

data("data_corpus_inaugural", package = "quanteda")
inaug_dfm <- quanteda::dfm(data_corpus_inaugural, verbose = FALSE)

inaug_dfm
```

```{r}
inaug_td <- tidy(inaug_dfm)
inaug_td
```

```{r}

inaug_tf_idf <- inaug_td %>%
  bind_tf_idf(term, document, count) %>% 
  arrange(desc(tf_idf))

inaug_tf_idf
  
```
```{r}

inaug_tf_idf %>% 
  filter(document %in% c("1861-Lincoln", "1933-Roosevelt", "1961-Kennedy", "2009-Obama")) %>% 
  ggplot(aes(reorder(term,tf_idf), tf_idf, fill = tf_idf)) +
  geom_col()+
  coord_flip()+
  facet_wrap(~document)
```

